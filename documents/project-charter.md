# **데이터 분석 통합 시스템 프로젝트 계획서**

---

## **1. 프로젝트 개요**

### **프로젝트 이름**  
**데이터 분석 통합 시스템 구축**

### **프로젝트 목표**    

**Kafka**, **Airflow**, **Impala**, **HDFS**, **PostgreSQL**, **Kafka Connect**, **Kafka Viewer**, **Grafana**, **Kibana**, **Jupyter Notebooks**와 같은 도구를 사용하여 학습, 실험, 프로토타이핑을 위한 로컬 데이터 분석 파이프라인을 설계하고 배포합니다.  
이 시스템은 Docker를 활용하여 컨테이너화된 배포 환경에서 **Kaggle 데이터셋**을 활용하여 수집, 처리, 저장, 쿼리 및 시각화하는 기능을 제공합니다.
---

## **2. 범위**

### **포함 범위**  
1. **데이터 수집**  
   - Apache Kafka를 사용한 실시간 데이터 스트리밍.  
   - Kafka Connect를 사용하여 HDFS와 PostgreSQL 등 외부 시스템과의 통합.

2. **데이터 저장**  
   - 대용량 데이터셋을 위한 분산 저장 HDFS.  
   - 구조화된 데이터를 위한 관계형 데이터베이스 저장 PostgreSQL.

3. **데이터 처리 및 쿼리**  
   - Apache Airflow를 이용한 ETL 파이프라인.
   - Python 기반의 변환 작업 지원.
   - Impala를 활용한 대규모 데이터 쿼리 실행 및 최적화.

4. **모니터링 및 디버깅**  
   - Kibana와 Grafana를 사용한 로그 및 시스템 모니터링.  
   - Kafka Viewer를 사용한 Kafka 토픽 검사.

5. **데이터 탐색 및 시각화**  
   - Jupyter Notebooks을 사용한 데이터 탐색 및 분석.  
   - Tableau를 사용한 데이터 시각화.

### **제외 범위**  
1. Kafka와 HDFS의 고급 클러스터링 또는 분산 설정.  
2. 클라우드 저장소 또는 클라우드 기반 HDFS 솔루션과의 통합.
3. 생산 환경 수준의 보안 구성.

---

## **3. 목표 및 결과물**

### **목표**  
- Kaggle 데이터셋을 저장하고 쿼리할 수 있는 완전한 로컬 데이터 파이프라인 구축.  
- Docker를 통한 구성 요소 간 원활한 데이터 흐름 구현.

### **결과물**  
1. **프로젝트 파일 구조**:  
   - 구성 파일, 스크립트, 로그 및 notebook을 위한 조직화된 디렉터리.

2. **Docker Compose 설정**:  
   - 모든 서비스를 조정하는 docker-compose.yml 파일.
   - 일부 서비스에 대해 별도의 docker-compose.yml 파일을 작성하여 개별적으로 설정 및 조정.

3. **ETL 파이프라인**:  
   - 데이터 수집, 변환 및 저장을 보여주는 Airflow DAG.

4. **샘플 데이터셋 통합**:  
   - 데이터 흐름을 보여주는 Kafka 생산자 및 소비자 스크립트.
   - Kafka와 PostgreSQL 간 데이터를 이동시키는 커넥터 구성.
   - Kaggle 데이터셋을 분석 및 시각화하는 코드.

---

## **4. 역할 및 책임**

| **역할**                   | **책임**                                                         |
|----------------------------|------------------------------------------------------------------|
| **프로젝트 관리자**          | 요구 사항 정의, 피드백 제공 및 결과물 검토.                     |
| **시스템 관리자**            | Docker 컨테이너 설정 및 관리.                                    |
| **데이터 엔지니어**          | Kafka, HDFS, Airflow 및 Impala 파이프라인 설정.                  |
| **데이터 분석가**            | 데이터 분석 수행 및 시각화 생성.                                 |

---

## **5. 타임라인**

| **단계**                    | **작업**                                           | **예상 시간**  |
|-----------------------------|--------------------------------------------------|----------------|
| **1단계: 계획**              | 프로젝트 범위 및 파일 구조 정의.                   | 1일            |
| **2단계: 설정**              | Docker 컨테이너 설치 및 구성.                      | 2일            |
| **3단계: 통합**              | 구성 요소 연결 및 데이터 흐름 확인.               | 2일            |
| **4단계: 검증**              | 파이프라인, HDFS 쿼리 및 모니터링 테스트.          | 2일            |
| **5단계: 데이터 분석**       | 데이터 탐색 및 분석 수행, 시각화 대시보드 생성.     | 5일            |

---

## **6. 기술 요구사항**

### **하드웨어**  
- 최소:  
  - **프로세서**:  
  - **메모리**:  
  - **저장공간**: 

- 권장:  
  - **프로세서**: 
  - **메모리**: 
  - **저장공간**: 

### **소프트웨어**  
- **운영 체제**: Windows 10/11  
- **도구**:  
  - **Docker Desktop** (WSL 2 통합)  
  - **Hadoop/HDFS** (분산 저장을 위한)  
  - **Python** (Airflow와 Jupyter에서 스크립팅 용) 
  - **PostgreSQL** 클라이언트 도구 (예: DataGrip 또는 pgAdmin).

---

## **7. 리스크 및 완화 전략**

| **리스크**                        | **영향**          | **완화 전략**                                           |
|-----------------------------------|-------------------|--------------------------------------------------------|
| Windows OS와의 호환성 문제       | 중간             | Docker 컨테이너를 사용하여 의존성을 격리.               |
| 높은 리소스 소비                  | 중간             | `docker-compose.yml`에서 컨테이너 리소스 제한.          |
| HDFS로 인한 리소스 제약          | 높음             | 테스트용으로 작은 Kaggle 데이터셋을 사용.              |
| 잘못 구성된 구성 요소           | 높음             | 작은 테스트 파이프라인으로 구성을 검증.                |

---

## **8. 성공 기준**

- 모든 서비스가 로컬에서 오류 없이 실행됨.  
- Kaggle 데이터셋이 Kafka, PostgreSQL, HDFS, Airflow를 통해 흐름.  
- Kibana, Grafana 및 Tableau에서 시각화 및 대시보드가 정상 작동.
- 기본 쿼리와 ETL 프로세스가 성공적으로 실행됨.

---

## **9. 부록**

### **프로젝트 구조**
```plaintext
data-analysis-project/
├── dags/                 
├── documents/                 
├── kafka/                  
├── hdfs/       
├── postgres/               
├── scripts/                
├── notebooks/              
├── grafana/                
├── kibana/                 
├── logs/                   
├── impala/   
├── .env
├── .gitignore
├── docker-compose.yml        
├── README.md   
```

### **샘플 명령어**
- 모든 서비스 시작:  
  ```bash
  docker-compose up -d
  ```

